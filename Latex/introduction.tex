Video is a very effective information container and it is a highly expressive type of media, capable of providing a large semantic load by presenting different audiovisual components coherently\cite{162960}. However, video can be considerably more useful when carrying metadata that can be used by video applications, and are often represented as video annotations.

Video annotation involves inserting tags into video objects to describe their content and context, also to describing media characteristics such as quality, coding, among other features \cite{Wang:2009:BDM:1652990.1653002}. In other words, they are used to facilitate the work of users and systems that can handle annotated items.

Annotations facilitate the manipulation of videos, allowing the creation of content-based distribution applications \cite{Zhang:2012:KIE:2339530.2339620}, indexing \cite{Zhang:2007:PRS:1290082.1290126}, summarization \cite{Fiao:2016:AGS:3001773.3001802}, navigation \cite{Goldman:2008}, composition \cite{Wilk:2015:VCC:2713168.2713178}, among many others by both automatic and manual means \cite{Wang:2011:ALM:1899412.1899414}. In other words, they are used to facilitate the work of users and systems that can handle annotated items.

In this paper, video annotations are categorized as simple and complex ones, considering that simple annotations are those that can be acquired with a simple interaction of the workers in a microtask. In addition, a complex annotation is one that requires the worker execute a more tedious, hard or time-consuming task, in which he needs to perform multiple interactions. 

A frequent problem of using a crowdsourcing approach to video annotation is to balance the relation between task complexity and cost. Simple annotation tasks, such as clicking an object on a video, can be done in a few seconds for anyone, otherwise, more complex tasks such as providing complementary content and positioning it in the right position on a video, require some expertise of contributors and are more costly to them. In a crowdsourcing context, microtask is an ubiquitous designation for simple tasks that can be performed for any contributor quick and easily \cite{Difallah:2015:DMC:2736277.2741685}.

CrowdNote is a crowdsourcing environment capable to achieve complex video annotation without the need for specialized nor trained workers, and it can be used as template to build different crowdsourcing applications based on video annotation. The system presented in this paper is a CrowdNote instance that produces enriched versions of videos in which are incorporated extra content such as images, text boxes, Wikipedia content and Youtube videos. 

The remaining of this paper is structured as follows. Section 2 presents the CrowdNote architecture. Section 3 presents the CrowdNote instance for video enrichmen. Finally, section 4 concludes the paper presenting final considerations.
